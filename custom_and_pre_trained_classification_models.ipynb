{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 22:18:43.067582: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D, Input, Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images are stored in the current working directory\n",
    "curr_dir = os.getcwd()\n",
    "data_folder_path = os.path.join(curr_dir, 'dataset')\n",
    "dataset_path = os.path.join(data_folder_path, 'Brain Tumor Data Set')\n",
    "\n",
    "healthy_brain_images_path = os.path.join(dataset_path, 'Healthy')\n",
    "brain_tumor_images_path = os.path.join(dataset_path, 'Brain Tumor')\n",
    "\n",
    "training_metadata_file_path = os.path.join(data_folder_path, 'metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "      <th>format</th>\n",
       "      <th>mode</th>\n",
       "      <th>shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cancer (1).jpg</td>\n",
       "      <td>tumor</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>RGB</td>\n",
       "      <td>(512, 512, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Cancer (10).jpg</td>\n",
       "      <td>tumor</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>RGB</td>\n",
       "      <td>(512, 512, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Cancer (100).jpg</td>\n",
       "      <td>tumor</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>RGB</td>\n",
       "      <td>(512, 512, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Cancer (1000).jpg</td>\n",
       "      <td>tumor</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>RGB</td>\n",
       "      <td>(290, 250, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Cancer (1001).jpg</td>\n",
       "      <td>tumor</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>RGB</td>\n",
       "      <td>(620, 620, 3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              image  class format mode          shape\n",
       "0           0     Cancer (1).jpg  tumor   JPEG  RGB  (512, 512, 3)\n",
       "3           3    Cancer (10).jpg  tumor   JPEG  RGB  (512, 512, 3)\n",
       "5           5   Cancer (100).jpg  tumor   JPEG  RGB  (512, 512, 3)\n",
       "6           6  Cancer (1000).jpg  tumor   JPEG  RGB  (290, 250, 3)\n",
       "7           7  Cancer (1001).jpg  tumor   JPEG  RGB  (620, 620, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_metdata_df = pd.read_csv(training_metadata_file_path)\n",
    "training_metdata_df = training_metdata_df[training_metdata_df[\"image\"].str.contains(\"jpg\")]\n",
    "training_metdata_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4432\n"
     ]
    }
   ],
   "source": [
    "print(len(training_metdata_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_training_metadata_df = training_metdata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For faster training reduce dataset size\n",
    "# import random\n",
    "\n",
    "# new_training_metadata_df = pd.DataFrame()\n",
    "\n",
    "# non_healthy_data = training_metdata_df[training_metdata_df[\"class\"] == \"tumor\"]\n",
    "# healthy_data = training_metdata_df[training_metdata_df[\"class\"] == \"normal\"]\n",
    "# print(len(healthy_data), len(non_healthy_data), len(non_healthy_data) + len(healthy_data))\n",
    "\n",
    "# random_non_healthy_data = random.sample(list(non_healthy_data[\"image\"].values), 1000)\n",
    "# random_healthy_data = random.sample(list(non_healthy_data[\"image\"].values), 1200)\n",
    "\n",
    "# def get_row_from_image_id(image_id):\n",
    "#     return training_metdata_df[training_metdata_df[\"image\"] == image_id]\n",
    "\n",
    "# for image_id in random_non_healthy_data:\n",
    "#     row = get_row_from_image_id(image_id)\n",
    "#     new_training_metadata_df = new_training_metadata_df.append(row, ignore_index=True)\n",
    "\n",
    "# for image_id in random_healthy_data:\n",
    "#     row = get_row_from_image_id(image_id)\n",
    "#     new_training_metadata_df = new_training_metadata_df.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "EPOCHS = 3 \n",
    "INPUT_SHAPE = (256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, test_ids = train_test_split(new_training_metadata_df[\"image\"], test_size = TEST_SIZE, random_state = RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3545, 887)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ids), len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, size=(256, 256)):\n",
    "    resized_image = image.resize(size)\n",
    "    return resized_image.convert(\"RGB\")\n",
    "\n",
    "def load_image(image_path):\n",
    "    return Image.open(image_path)\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    return image.rotate(angle, expand=True)\n",
    "\n",
    "def flip_image(image):\n",
    "    return image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "def convert_image_to_numpy_array(image):\n",
    "    return np.array(image)\n",
    "\n",
    "def load_images(image_ids):\n",
    "    X_classification = []\n",
    "    y_classification = []\n",
    "\n",
    "    for image_id in image_ids:\n",
    "        if \"Not Cancer\" in image_id:\n",
    "            image_path = healthy_brain_images_path + \"/\" + image_id\n",
    "        else:\n",
    "            image_path = brain_tumor_images_path + \"/\" + image_id\n",
    "\n",
    "        image = load_image(image_path)\n",
    "        image_resized = resize_image(image)\n",
    "\n",
    "        classification_label = new_training_metadata_df[new_training_metadata_df['image'] == image_id]['class'].values[0]\n",
    "        if classification_label == \"tumor\":\n",
    "            classification_label = 1\n",
    "        else:\n",
    "            classification_label = 0\n",
    "\n",
    "        rotated_image_60 = resize_image(rotate_image(image, 60))\n",
    "        rotated_image_120 = resize_image(rotate_image(image, 120))\n",
    "\n",
    "        flipped_image_original = flip_image(image_resized)\n",
    "        flipped_image_60 = flip_image(rotated_image_60)\n",
    "        flipped_image_120 = flip_image(rotated_image_120)\n",
    "\n",
    "        # print(\"Image Resized Shape:\", np.array(image_resized).shape)\n",
    "        # print(\"Rotated Image 60 Shape:\", np.array(rotated_image_60).shape)\n",
    "        # print(\"Rotated Image 120 Shape:\", np.array(rotated_image_120).shape)\n",
    "        # print(\"Flipped Image Original Shape:\", np.array(flipped_image_original).shape)\n",
    "        # print(\"Flipped Image 60 Shape:\", np.array(flipped_image_60).shape)\n",
    "        # print(\"Flipped Image 120 Shape:\", np.array(flipped_image_120).shape)\n",
    "\n",
    "        X_classification.extend([convert_image_to_numpy_array(image_resized),\n",
    "                                 convert_image_to_numpy_array(rotated_image_60),\n",
    "                                 convert_image_to_numpy_array(rotated_image_120),\n",
    "                                 convert_image_to_numpy_array(flipped_image_original),\n",
    "                                 convert_image_to_numpy_array(flipped_image_60),\n",
    "                                 convert_image_to_numpy_array(flipped_image_120)])\n",
    "        y_classification.extend([classification_label] * 6)\n",
    "\n",
    "        # X_classification.append(image_resized)\n",
    "        # y_classification.append(classification_label)\n",
    "\n",
    "    return np.array(X_classification), np.array(y_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_images(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = load_images(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (21270, 256, 256, 3)\n",
      "Shape of y_train: (21270,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_val: (5322, 256, 256, 3)\n",
      "Shape of y_val: (5322,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_val:\", X_test.shape)\n",
    "print(\"Shape of y_val:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='accuracy', patience=2, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build, Train and Predict using Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 256, 256, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 128, 128, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 64, 64, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 131072)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8388672   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8398881 (32.04 MB)\n",
      "Trainable params: 8398881 (32.04 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Basic convolutional neural network (CNN) Model\n",
    "def create_classification_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    flatten = Flatten()(pool2)\n",
    "    dense1 = Dense(64, activation='relu')(flatten)\n",
    "    outputs = Dense(1, activation='sigmoid')(dense1)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "classification_model = create_classification_model(INPUT_SHAPE)\n",
    "classification_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "665/665 [==============================] - 528s 791ms/step - loss: 2.6714 - accuracy: 0.8385\n",
      "Epoch 2/3\n",
      "665/665 [==============================] - 512s 771ms/step - loss: 0.1100 - accuracy: 0.9636\n",
      "Epoch 3/3\n",
      "665/665 [==============================] - 516s 776ms/step - loss: 0.0479 - accuracy: 0.9866\n"
     ]
    }
   ],
   "source": [
    "history = classification_model.fit(X_train, y_train, epochs=EPOCHS, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 30s 177ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = classification_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = (y_pred > 0.5).astype(int)\n",
    "# y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9569710635099586\n",
      "Precision: 0.9702602230483272\n",
      "Recall: 0.953187250996016\n",
      "F1 Score: 0.961647965164964\n",
      "AUC Score: 0.9575460064503889\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
    "precision = metrics.precision_score(y_test, y_pred_class)\n",
    "recall = metrics.recall_score(y_test, y_pred_class)\n",
    "f1_score = metrics.f1_score(y_test, y_pred_class)\n",
    "auc_score = metrics.roc_auc_score(y_test, y_pred_class)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"AUC Score: {auc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2222   88]\n",
      " [ 141 2871]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model on ResNet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_training_images_subset(train_size):\n",
    "    return X_train[:train_size], y_train[:train_size]\n",
    "\n",
    "def take_test_images_subset(test_size):\n",
    "    return X_test[:test_size], y_test[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, y_train1 = take_training_images_subset(train_size=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1, y_test1 = take_test_images_subset(test_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (3000, 256, 256, 3)\n",
      "Shape of y_train: (3000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train:\", X_train1.shape)\n",
    "print(\"Shape of y_train:\", y_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_val: (500, 256, 256, 3)\n",
      "Shape of y_val: (500,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_val:\", X_test1.shape)\n",
    "print(\"Shape of y_val:\", y_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "image_size = 256\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet101 model without the top (fully connected) layers\n",
    "base_model = tf.keras.applications.ResNet101(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3), pooling=None)\n",
    "\n",
    "# Freeze the layers of the pre-trained ResNet101 model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build your custom model on top of the pre-trained ResNet101\n",
    "resnet101_model = Sequential()\n",
    "resnet101_model.add(base_model)\n",
    "resnet101_model.add(GlobalMaxPooling2D())  # Use GlobalMaxPooling2D instead of MaxPooling2D\n",
    "resnet101_model.add(Dense(512, activation='relu'))\n",
    "resnet101_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "resnet101_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet101 (Functional)      (None, 8, 8, 2048)        42658176  \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 2048)              0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               1049088   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 513       \n"
     ]
    }
   ],
   "source": [
    "# Print Model Summary\n",
    "resnet101_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(resnet101_model, to_file='resnet101_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model on traning dataset\n",
    "resnet101_model_history = resnet101_model.fit(X_train1, y_train1, epochs=3, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform predictions\n",
    "y_pred_resnet101_model = resnet101_model.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class_resnet101_model = (y_pred_resnet101_model > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet101_model_accuracy = metrics.accuracy_score(y_test1, y_pred_class_resnet101_model)\n",
    "resnet101_model_precision = metrics.precision_score(y_test1, y_pred_class_resnet101_model)\n",
    "resnet101_model_recall = metrics.recall_score(y_test1, y_pred_class_resnet101_model)\n",
    "resnet101_model_f1_score = metrics.f1_score(y_test1, y_pred_class_resnet101_model)\n",
    "resnet101_model_auc_score = metrics.roc_auc_score(y_test1, y_pred_class_resnet101_model)\n",
    "\n",
    "print(f\"Accuracy: {resnet101_model_accuracy}\")\n",
    "print(f\"Precision: {resnet101_model_precision}\")\n",
    "print(f\"Recall: {resnet101_model_recall}\")\n",
    "print(f\"F1 Score: {resnet101_model_f1_score}\")\n",
    "print(f\"AUC Score: {resnet101_model_auc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet101_model_confusion_matrix = metrics.confusion_matrix(y_test1, y_pred_class_resnet101_model)\n",
    "print(resnet101_model_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model on VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained VGG19 model without the top (fully connected) layers\n",
    "base_model = tf.keras.applications.VGG19(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3), pooling=None)\n",
    "\n",
    "# Freeze the layers of the pre-trained VGG19 model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build custom model on top of the pre-trained VGG19\n",
    "vgg19_model = Sequential()\n",
    "vgg19_model.add(base_model)\n",
    "vgg19_model.add(GlobalMaxPooling2D())\n",
    "vgg19_model.add(Dense(512, activation='relu'))\n",
    "vgg19_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "vgg19_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Model Summary\n",
    "vgg19_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(vgg19_model, to_file='vgg19_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model on traning dataset\n",
    "vgg19_model_history = vgg19_model.fit(X_train1, y_train1, epochs=3, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform predictions\n",
    "y_pred_vgg19_model = vgg19_model.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class_vgg19_model = (y_pred_vgg19_model > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_model_accuracy = metrics.accuracy_score(y_test1, y_pred_class_vgg19_model)\n",
    "vgg19_model_precision = metrics.precision_score(y_test1, y_pred_class_vgg19_model)\n",
    "vgg19_model_recall = metrics.recall_score(y_test1, y_pred_class_vgg19_model)\n",
    "vgg19_model_f1_score = metrics.f1_score(y_test1, y_pred_class_vgg19_model)\n",
    "vgg19_model_auc_score = metrics.roc_auc_score(y_test1, y_pred_class_vgg19_model)\n",
    "\n",
    "print(f\"Accuracy: {vgg19_model_accuracy}\")\n",
    "print(f\"Precision: {vgg19_model_precision}\")\n",
    "print(f\"Recall: {vgg19_model_recall}\")\n",
    "print(f\"F1 Score: {vgg19_model_f1_score}\")\n",
    "print(f\"AUC Score: {vgg19_model_auc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_model_confusion_matrix = metrics.confusion_matrix(y_test1, y_pred_class_vgg19_model)\n",
    "print(vgg19_model_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model on Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained Xception model without the top (fully connected) layers\n",
    "base_model = tf.keras.applications.Xception(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3), pooling=None)\n",
    "\n",
    "# Freeze the layers of the pre-trained Xception model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build custom model on top of the pre-trained Xception\n",
    "xception_model = Sequential()\n",
    "xception_model.add(base_model)\n",
    "xception_model.add(GlobalMaxPooling2D())\n",
    "xception_model.add(Dense(512, activation='relu'))\n",
    "xception_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "xception_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Model Summary\n",
    "xception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(xception_model, to_file='xception_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model on traning dataset\n",
    "xception_model_history = xception_model.fit(X_train1, y_train1, epochs=3, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform predictions\n",
    "y_pred_xception_model = xception_model.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class_xception_model = (y_pred_xception_model > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception_model_accuracy = metrics.accuracy_score(y_test1, y_pred_class_xception_model)\n",
    "xception_model_precision = metrics.precision_score(y_test1, y_pred_class_xception_model)\n",
    "xception_model_recall = metrics.recall_score(y_test1, y_pred_class_xception_model)\n",
    "xception_model_f1_score = metrics.f1_score(y_test1, y_pred_class_xception_model)\n",
    "xception_model_auc_score = metrics.roc_auc_score(y_test1, y_pred_class_xception_model)\n",
    "\n",
    "print(f\"Accuracy: {xception_model_accuracy}\")\n",
    "print(f\"Precision: {xception_model_precision}\")\n",
    "print(f\"Recall: {xception_model_recall}\")\n",
    "print(f\"F1 Score: {xception_model_f1_score}\")\n",
    "print(f\"AUC Score: {xception_model_auc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception_model_confusion_matrix = metrics.confusion_matrix(y_test1, y_pred_class_xception_model)\n",
    "print(xception_model_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model on MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained MobileNetV2 model without the top (fully connected) layers\n",
    "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3), pooling=None, classifier_activation=\"softmax\")\n",
    "\n",
    "# Freeze the layers of the pre-trained MobileNetV2 model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build custom model on top of the pre-trained MobileNetV2\n",
    "mobilenet_model = Sequential()\n",
    "mobilenet_model.add(base_model)\n",
    "mobilenet_model.add(GlobalMaxPooling2D())\n",
    "mobilenet_model.add(Dense(512, activation='relu'))\n",
    "mobilenet_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "mobilenet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Model Summary\n",
    "mobilenet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(mobilenet_model, to_file='mobilenet_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model on traning dataset\n",
    "history = mobilenet_model.fit(X_train1, y_train1, epochs=3, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform predictions\n",
    "y_pred = mobilenet_model.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = (y_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_model_accuracy = metrics.accuracy_score(y_test1, y_pred_class)\n",
    "mobilenet_model_precision = metrics.precision_score(y_test1, y_pred_class)\n",
    "mobilenet_model_recall = metrics.recall_score(y_test1, y_pred_class)\n",
    "mobilenet_model_f1_score = metrics.f1_score(y_test1, y_pred_class)\n",
    "mobilenet_model_auc_score = metrics.roc_auc_score(y_test1, y_pred_class)\n",
    "\n",
    "print(f\"Accuracy: {mobilenet_model_accuracy}\")\n",
    "print(f\"Precision: {mobilenet_model_precision}\")\n",
    "print(f\"Recall: {mobilenet_model_recall}\")\n",
    "print(f\"F1 Score: {mobilenet_model_f1_score}\")\n",
    "print(f\"AUC Score: {mobilenet_model_auc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_model_confusion_matrix = metrics.confusion_matrix(y_test1, y_pred_class)\n",
    "print(mobilenet_model_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
